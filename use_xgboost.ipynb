{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例代码\n",
    "# from xgboost import XGBClassifier\n",
    "# # read data\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# data = load_iris()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=.2)\n",
    "# # create model instance\n",
    "# bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "# # fit model\n",
    "# bst.fit(X_train, y_train)\n",
    "# # make predictions\n",
    "# preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_dif_p1</th>\n",
       "      <th>score_dif_p2</th>\n",
       "      <th>server_p1</th>\n",
       "      <th>server_p2</th>\n",
       "      <th>p1_ad</th>\n",
       "      <th>p2_ad</th>\n",
       "      <th>p1_comble</th>\n",
       "      <th>p2_comble</th>\n",
       "      <th>p1_break_points</th>\n",
       "      <th>p2_break_points</th>\n",
       "      <th>p1_break_points_won</th>\n",
       "      <th>p2_break_points_won</th>\n",
       "      <th>p1_win_possiblity</th>\n",
       "      <th>p2_win_possiblity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>-0.810852</td>\n",
       "      <td>0.810852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.420574</td>\n",
       "      <td>-0.381385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>-0.638412</td>\n",
       "      <td>0.638412</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.420574</td>\n",
       "      <td>-0.381385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>-0.810852</td>\n",
       "      <td>0.810852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.510632</td>\n",
       "      <td>-0.381385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>-0.638412</td>\n",
       "      <td>0.638412</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.420574</td>\n",
       "      <td>-0.381385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>-0.810852</td>\n",
       "      <td>0.810852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.420574</td>\n",
       "      <td>-0.381385</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score_dif_p1  score_dif_p2  server_p1  server_p2  p1_ad  p2_ad  \\\n",
       "3788     -0.810852      0.810852          0          1      0      0   \n",
       "3789     -0.638412      0.638412          0          1      0      0   \n",
       "3790     -0.810852      0.810852          0          1      0      0   \n",
       "3791     -0.638412      0.638412          0          1      0      0   \n",
       "3792     -0.810852      0.810852          0          1      0      0   \n",
       "\n",
       "      p1_comble  p2_comble  p1_break_points  p2_break_points  \\\n",
       "3788  -0.420574  -0.381385                0                0   \n",
       "3789  -0.420574  -0.381385                0                0   \n",
       "3790   1.510632  -0.381385                0                0   \n",
       "3791  -0.420574  -0.381385                0                0   \n",
       "3792  -0.420574  -0.381385                1                0   \n",
       "\n",
       "      p1_break_points_won  p2_break_points_won  p1_win_possiblity  \\\n",
       "3788                    0                    0                  3   \n",
       "3789                    0                    0                  2   \n",
       "3790                    0                    0                  1   \n",
       "3791                    0                    0                  1   \n",
       "3792                    0                    0                  0   \n",
       "\n",
       "      p2_win_possiblity  \n",
       "3788                  2  \n",
       "3789                  3  \n",
       "3790                  4  \n",
       "3791                  4  \n",
       "3792                  5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"2024c/traintestds/2023-wimbledon-1401\", index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_concat(dir_path='2024c/traintestds/', df_all_in_one_pth=None):\n",
    "    if df_all_in_one_pth != None:\n",
    "        df_list = [read_csv(df_all_in_one_pth,index_col=[0])]\n",
    "    else:\n",
    "        df_list = [read_csv(dir_path+fn,index_col=[0]) for fn in os.listdir(dir_path)]\n",
    "    x_list, y_list = [], []\n",
    "    for df in df_list:\n",
    "        df = df.drop('score_dif_p2\tserver_p2\tp1_ad p2_ad p1_break_points p2_break_points \tp1_break_points_won p2_break_points_won'.split(), axis=1)\n",
    "        x = []# 特征数据\n",
    "        y = []# 标签\n",
    "        for index in df.index.values:\n",
    "            # print(df.loc[index].values) \n",
    "            x.append(df.loc[index].values[:-2])\n",
    "            y.append(df.loc[index].values[-2])\n",
    "        x, y = np.array(x), np.array(y)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "    return np.concatenate(x_list), np.concatenate(y_list).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = ds_concat()\n",
    "Ymean, Ystd = Y.mean(), Y.std()\n",
    "n = len(Y)\n",
    "x, y = X[:300], Y[:300]\n",
    "x_train, x_test = X[:-n//8], X[-n//8:]\n",
    "y_train, y_test = Y[:-n//8], Y[-n//8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 911\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgboost\n",
    "# from xgboost import XGBClassifier\n",
    "# xgbc_model=XGBClassifier()\n",
    "\n",
    "# # 随机森林\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc_model=RandomForestClassifier()\n",
    "\n",
    "# # ET\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# et_model=ExtraTreesClassifier()\n",
    "\n",
    "# # 朴素贝叶斯\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb_model=GaussianNB()\n",
    "\n",
    "# #K最近邻\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn_model=KNeighborsClassifier()\n",
    "\n",
    "#逻辑回归\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# lr_model=LogisticRegression()\n",
    "\n",
    "# #决策树\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# dt_model=DecisionTreeClassifier()\n",
    "\n",
    "# #支持向量机\n",
    "# from sklearn.svm import SVC\n",
    "# svc_model=SVC()\n",
    "\n",
    "# # xgboost\n",
    "# xgbc_model.fit(x,y)\n",
    "\n",
    "# # 随机森林\n",
    "# rfc_model.fit(x,y)\n",
    "\n",
    "# # ET\n",
    "# et_model.fit(x,y)\n",
    "\n",
    "# # 朴素贝叶斯\n",
    "# gnb_model.fit(x,y)\n",
    "\n",
    "# # K最近邻\n",
    "# knn_model.fit(x,y)\n",
    "\n",
    "# # 逻辑回归\n",
    "# lr_model.fit(x,y)\n",
    "\n",
    "# # 决策树\n",
    "# dt_model.fit(x,y)\n",
    "\n",
    "# # 支持向量机\n",
    "# svc_model.fit(x,y)\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# print(\"\\n使用５折交叉验证方法得随机森林模型的准确率（每次迭代的准确率的均值）：\")\n",
    "# print(\"\\tXGBoost模型：\",cross_val_score(xgbc_model,x,y,cv=5).mean())\n",
    "# print(\"\\t随机森林模型：\",cross_val_score(rfc_model,x,y,cv=5).mean())\n",
    "# print(\"\\tET模型：\",cross_val_score(et_model,x,y,cv=5).mean())\n",
    "# print(\"\\t高斯朴素贝叶斯模型：\",cross_val_score(gnb_model,x,y,cv=5).mean())\n",
    "# print(\"\\tK最近邻模型：\",cross_val_score(knn_model,x,y,cv=5).mean())\n",
    "# print(\"\\t逻辑回归：\",cross_val_score(lr_model,x,y,cv=5).mean())\n",
    "# print(\"\\t决策树：\",cross_val_score(dt_model,x,y,cv=5).mean())\n",
    "# print(\"\\t支持向量机：\",cross_val_score(svc_model,x,y,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能评估以XGboost为例\n",
    "# xgb = XGBRegressor()\n",
    "# # 对训练集训练模型\n",
    "# xgb.fit(x_train, y_train)\n",
    "\n",
    "# # 对测试集进行预测\n",
    "# y_pred = xgb.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = y_pred\n",
    "# y_test = y_test\n",
    "# abs(y_pred - y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(y_test[:100], color='red')\n",
    "# plt.plot(y_pred[:100], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.95307831,  1.        , -0.40824829, -0.39090011])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 189000 candidates, totalling 945000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params, fine_params\n\u001b[0;32m     53\u001b[0m adj_params, fixed_params \u001b[38;5;241m=\u001b[39m xgboost_parameters()\n\u001b[1;32m---> 54\u001b[0m \u001b[43mmodel_adjust_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mmodel_adjust_parameters\u001b[1;34m(cv_params, other_params)\u001b[0m\n\u001b[0;32m      6\u001b[0m optimized_param \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mcv_params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 模型训练\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43moptimized_param\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 对应参数的k折交叉验证平均得分\u001b[39;00m\n\u001b[0;32m     10\u001b[0m means \u001b[38;5;241m=\u001b[39m optimized_param\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:890\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 890\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lithium\\OneDrive\\桌面\\preMCM\\.env\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def model_adjust_parameters(cv_params, other_params):\n",
    "    \"\"\"模型调参\"\"\"\n",
    "    # 模型基本参数\n",
    "    model = XGBClassifier(**other_params)\n",
    "    # sklearn提供的调参工具，训练集k折交叉验证\n",
    "    optimized_param = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1)\n",
    "    # 模型训练\n",
    "    optimized_param.fit(x_train, y_train)\n",
    "    # 对应参数的k折交叉验证平均得分\n",
    "    means = optimized_param.cv_results_['mean_test_score']\n",
    "    params = optimized_param.cv_results_['params']\n",
    "    for mean, param in zip(means, params):\n",
    "        print(\"mean_score: %f,  params: %r\" % (mean, param))\n",
    "    # 最佳模型参数\n",
    "    print('参数的最佳取值：{0}'.format(optimized_param.best_params_))\n",
    "    # 最佳参数模型得分\n",
    "    print('最佳模型得分:{0}'.format(optimized_param.best_score_))\n",
    "\n",
    "    # 模型参数调整得分变化曲线绘制\n",
    "    parameters_score = pd.DataFrame(params, means)\n",
    "    parameters_score['means_score'] = parameters_score.index\n",
    "    parameters_score = parameters_score.reset_index(drop=True)\n",
    "    # parameters_score.to_excel('parameters_score.xlsx', index=False)\n",
    "    # 画图\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(parameters_score.iloc[:, :-1], 'o-')\n",
    "    plt.legend(parameters_score.columns.to_list()[:-1], loc='upper left')\n",
    "    plt.title('Parameters_size', loc='left', fontsize='xx-large', fontweight='heavy')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(parameters_score.iloc[:, -1], 'r+-')\n",
    "    plt.legend(parameters_score.columns.to_list()[-1:], loc='upper left')\n",
    "    plt.title('Score', loc='left', fontsize='xx-large', fontweight='heavy')\n",
    "    plt.show()\n",
    "def xgboost_parameters():\n",
    "    \"\"\"模型调参过程\"\"\"\n",
    "    # 第二步：min_child_weight 以及 max_depth\n",
    "    # 参数的最佳取值：{'max_depth': 2, 'min_child_weight': 1}\n",
    "    # 最佳模型得分:0.9180952380952381，模型分数未提高\n",
    "    params = {\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_child_weight': [1, 2, 3, 4, 5, 6],\n",
    "        'gamma':[0, 0.03, 0.05, 0.08, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "        'colsample_bytree':[0.3,0.5,0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"n_estimators\": [50,60,70,80,90,100,120,150,200], # 多少棵树\n",
    "        \"eta\": [0.05, 0.1, 0,2, 0.3], # 学习率\n",
    "        }\n",
    "\t\n",
    "\t# 其他参数设置，每次调参将确定的参数加入，不写即默认参数\n",
    "    fine_params = {'n_estimators': 50}\n",
    "    return params, fine_params\n",
    "    \n",
    "adj_params, fixed_params = xgboost_parameters()\n",
    "model_adjust_parameters(adj_params, fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 带上server标签时bst: n=188, m=10\n",
    "params = {'objective':'multi:softprob',\n",
    "    'n_estimators': 50, 'max_depth': 2, 'min_child_weight': 1, 'gamma': 0.1, 'colsample_bytree': 1,\n",
    "                'subsample': 1, 'reg_alpha': 0.01, 'reg_lambda': 3, 'learning_rate': 0.4}\n",
    "xgb= XGBClassifier(params)\n",
    "xgb.fit(x_train, y_train)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = -100\n",
    "y_train_pred = y_pred = xgb.predict(x_train)\n",
    "plt.plot(y_train[st:], color='red')\n",
    "plt.plot(y_train_pred[st:], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = xgb.predict(x_test)\n",
    "y_pred_prob = xgb.predict_proba(x_test)\n",
    "y_pred_prob_mean = []\n",
    "for j in y_pred_prob:\n",
    "    cur = 0\n",
    "    for i in range(6):\n",
    "        cur += j[i]*i\n",
    "    y_pred_prob_mean.append(cur)\n",
    "y_pred_prob_mean = np.array(y_pred_prob_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 600\n",
    "end = 700\n",
    "plt.plot(y_test[start:end], color='red')\n",
    "plt.plot(y_pred[start:end], color='green')\n",
    "# plt.plot(y_pred_prob_mean[start:], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "final_acc = 0\n",
    "final_acc_win_ldx = []\n",
    "final_acc_loss_ldx = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]>2.5 and y_test[i]>2.5 or y_pred[i]<2.5 and y_test[i]<2.5:\n",
    "        final_acc += 1\n",
    "        if y_pred[i]>2.5 and y_test[i]>2.5: final_acc_win_ldx.append(i)\n",
    "        if y_pred[i]<2.5 and y_test[i]<2.5: final_acc_loss_ldx.append(i)\n",
    "    if y_pred[i]==y_test[i]:\n",
    "        acc += 1\n",
    "print(\"acc: {}\".format(acc*100/len(y_pred)))\n",
    "print(\"final_acc: {}\".format(final_acc*100/len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test[start:end], color='blue')\n",
    "xwplot = [i-start for i in final_acc_win_ldx if end > i >= start]\n",
    "xlplot = [i-start for i in final_acc_loss_ldx if end > i >= start]\n",
    "plt.scatter(xwplot, [2.5]*(len(xwplot)), color='green')\n",
    "plt.scatter(xlplot, [2.5]*(len(xlplot)), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_selected(clf_model):\n",
    "    \"\"\"模型特征重要性提取与保存\"\"\"\n",
    "    # 模型特征重要性打印和保存\n",
    "    feature_importance = clf_model.get_booster().get_fscore()\n",
    "    feature_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    # feature_ipt = pd.DataFrame(feature_importance, columns=['特征名称', '重要性'])\n",
    "    # feature_ipt.to_csv('feature_importance.csv', index=False)\n",
    "    print('特征重要性:', feature_importance)\n",
    "\n",
    "    # 模型特征重要性绘图\n",
    "    plot_importance(xgb)\n",
    "    plt.show()\n",
    "\n",
    "feature_importance_selected(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,roc_curve\n",
    "def metrics_sklearn(y_valid, y_pred_):\n",
    "    \"\"\"模型对验证集和测试集结果的评分\"\"\"\n",
    "    # 准确率\n",
    "    accuracy = accuracy_score(y_valid, y_pred_)\n",
    "    print('Accuracy：%.2f%%' % (accuracy * 100))\n",
    "\n",
    "    # 精准率\n",
    "    precision = precision_score(y_valid, y_pred_)\n",
    "    print('Precision：%.2f%%' % (precision * 100))\n",
    "\n",
    "    # 召回率\n",
    "    recall = recall_score(y_valid, y_pred_)\n",
    "    print('Recall：%.2f%%' % (recall * 100))\n",
    "\n",
    "    # F1值\n",
    "    f1 = f1_score(y_valid, y_pred_)\n",
    "    print('F1：%.2f%%' % (f1 * 100))\n",
    "\n",
    "    # auc曲线下面积\n",
    "    auc = roc_auc_score(y_valid, y_pred_)\n",
    "    print('AUC：%.2f%%' % (auc * 100))\n",
    "\n",
    "    # ks值\n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, y_pred_)\n",
    "    ks = max(abs(fpr - tpr))\n",
    "    print('KS：%.2f%%' % (ks * 100))\n",
    "metrics_sklearn(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
